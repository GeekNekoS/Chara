services:
  tensorflow_serving:
    image: tensorflow/serving:latest-gpu
    container_name: tf_serving
    ports:
      - "8501:8501"
    volumes:
      - ./models:/models
      - ./models.config:/models/models.config
    command: >
      tensorflow_model_server
      --model_config_file=/models/models.config
      --allow_version_labels_for_unavailable_models=true
      --rest_api_port=8501
    restart: always
    networks:
      - app_network

  django:
    build:
      context: .
      dockerfile: Dockerfile.django
    container_name: django_app
    ports:
      - "8000:8000"
    environment:
      # Задайте здесь переменные окружения, если нужно
      - DJANGO_ALLOWED_HOSTS=*
#    depends_on:
#      - tf_serving
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - .:/app  # Монтируем текущую директорию в контейнер
    networks:
      - app_network

networks:
  app_network:
    driver: bridge